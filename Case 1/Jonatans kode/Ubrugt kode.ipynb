{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gammel kode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "\n",
    "#load data from txt file with pandas\n",
    "data = pd.read_csv('case1Data.txt', sep=\", \", engine='python')\n",
    "y = data['y']\n",
    "\n",
    "X = pd.read_csv('case1Data_one_hot.csv').to_numpy()\n",
    "X_new = pd.read_csv('case1Data_Xnew_one_hot.csv').to_numpy()\n",
    "y_vec = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomScaler(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, X_new = None):\n",
    "        self.X_new = X_new\n",
    "        self.scaler = StandardScaler()\n",
    "\n",
    "    def fit(self, X, y = None):\n",
    "        self.scaler.fit(np.concatenate((X[:,:95], self.X_new[:,:95]), axis = 0))\n",
    "        #print('scaler fit')\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y = None):\n",
    "        X_con = self.scaler.transform(X[:,:95])\n",
    "        X = np.concatenate((X_con, X[:,95:]), axis = 1)\n",
    "        return X\n",
    "    \n",
    "class CustomKNNImputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_neighbors=1, weights='distance', X_new = None):\n",
    "        #print('CustomKNNImputer init')\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.weights = weights\n",
    "        self.X_new = X_new\n",
    "\n",
    "    def fit(self, X, y = None):\n",
    "        self.scaler = CustomScaler(X_new = self.X_new).fit(X)\n",
    "        X_new_norm = self.scaler.transform(self.X_new)\n",
    "        data = np.concatenate((X, X_new_norm), axis = 0)\n",
    "        self.imputer = KNNImputer(n_neighbors = self.n_neighbors, weights = self.weights)\n",
    "        self.imputer.fit(data)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y = None):\n",
    "        X = self.imputer.transform(X)\n",
    "        N = X.shape[0]\n",
    "        for i in range(N):\n",
    "            for j in range(4):\n",
    "                idx = np.argmax(X[i, 95+(j*5) : 95+(j+1)*5 ])\n",
    "                X[i, 95+(j*5) : 95+(j+1)*5 ] = 0,0,0,0,0\n",
    "                X[i, 95+(j*5) + idx] = 1\n",
    "        return X\n",
    "    \n",
    "class Debugger(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def transform(self, data):\n",
    "        print(\"Shape of data at this point\", data.shape)\n",
    "        print(pd.DataFrame(data).head())\n",
    "        return data\n",
    "\n",
    "    def fit(self, data, y=None, **fit_params):\n",
    "        # No need to fit anything, because this is not an actual  transformation. \n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Define the pipeline\n",
    "scaler = CustomScaler(X_new=X_new)\n",
    "imputer = CustomKNNImputer(X_new = X_new)\n",
    "model = Lasso(max_iter=10000)\n",
    "pipe = Pipeline(steps=[('scale', scaler), ('impute', imputer), ('model', model)])\n",
    "\n",
    "param_grid = {'impute__weights': ['uniform', 'distance'], \n",
    "              'impute__n_neighbors': range(3, 10), \n",
    "              'model__alpha': np.linspace(0.1, 3, 10)\n",
    "              }\n",
    "\n",
    "# Define the cross-validation\n",
    "K_outer = 5\n",
    "K_inner = 3\n",
    "outer_cv = KFold(n_splits=K_outer, shuffle=True, random_state=42)\n",
    "inner_cv = KFold(n_splits=K_inner, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform the grid search\n",
    "RMSE = np.zeros(K_outer)\n",
    "for i, (train_idx, test_idx) in enumerate(outer_cv.split(X)):\n",
    "    print(f\"Running outer fold {i+1}/{K_outer}\")\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y_vec[train_idx], y_vec[test_idx]\n",
    "    search = GridSearchCV(pipe, param_grid, cv=inner_cv, scoring='neg_mean_squared_error', n_jobs=-1, refit = True)\n",
    "    search.fit(X_train, y_train)\n",
    "    best_params = search.best_params_\n",
    "\n",
    "    pipe.set_params(**best_params)\n",
    "    pipe.fit(X_train, y_train)\n",
    "    preds = pipe.predict(X_test)\n",
    "\n",
    "    #best_model = result.best_estimator_\n",
    "    #preds = best_model.predict(X_test)\n",
    "\n",
    "    RMSE[i] = np.sqrt(np.mean((preds - y_test)**2))\n",
    "    print(\"Best parameter (CV score=%0.3f):\" % search.best_score_, search.best_params_, 'RMSE:', f\"{RMSE[i]:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
