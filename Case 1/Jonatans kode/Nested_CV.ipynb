{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nested CV using sklearn pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import KFold, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data from txt file with pandas\n",
    "data = pd.read_csv('case1Data.txt', sep=\", \", engine='python')\n",
    "y = data['y']\n",
    "\n",
    "X = pd.read_csv('case1Data_one_hot.csv').to_numpy()\n",
    "X_new = pd.read_csv('case1Data_Xnew_one_hot.csv').to_numpy()\n",
    "y_vec = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomScaler(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, X_new = None):\n",
    "        self.X_new = X_new\n",
    "        self.scaler = StandardScaler()\n",
    "\n",
    "    def fit(self, X, y = None):\n",
    "        self.scaler.fit(np.concatenate((X[:,:95], self.X_new[:,:95]), axis = 0))\n",
    "        #print('scaler fit')\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y = None):\n",
    "        X_con = self.scaler.transform(X[:,:95])\n",
    "        X = np.concatenate((X_con, X[:,95:]), axis = 1)\n",
    "        return X\n",
    "    \n",
    "class CustomKNNImputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_neighbors=1, weights='distance', X_new = None):\n",
    "        #print('CustomKNNImputer init')\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.weights = weights\n",
    "        self.X_new = X_new\n",
    "\n",
    "    def fit(self, X, y = None):\n",
    "        self.scaler = CustomScaler(X_new = self.X_new).fit(X)\n",
    "        X_new_norm = self.scaler.transform(self.X_new)\n",
    "        data = np.concatenate((X, X_new_norm), axis = 0)\n",
    "        self.imputer = KNNImputer(n_neighbors = self.n_neighbors, weights = self.weights)\n",
    "        self.imputer.fit(data)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y = None):\n",
    "        X = self.imputer.transform(X)\n",
    "        N = X.shape[0]\n",
    "        for i in range(N):\n",
    "            for j in range(4):\n",
    "                idx = np.argmax(X[i, 95+(j*5) : 95+(j+1)*5 ])\n",
    "                X[i, 95+(j*5) : 95+(j+1)*5 ] = 0,0,0,0,0\n",
    "                X[i, 95+(j*5) + idx] = 1\n",
    "        return X\n",
    "    \n",
    "class Debugger(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def transform(self, data):\n",
    "        print(\"Shape of data at this point\", data.shape)\n",
    "        print(pd.DataFrame(data).head())\n",
    "        return data\n",
    "\n",
    "    def fit(self, data, y=None, **fit_params):\n",
    "        # No need to fit anything, because this is not an actual  transformation. \n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running outer fold 1/5\n",
      "scaler fit\n",
      "scaler fit\n",
      "scaler fit\n",
      "scaler fit\n",
      "Best parameter (CV score=-588.466): {'impute__n_neighbors': 3, 'impute__weights': 'distance', 'model__alpha': 1.3888888888888888} RMSE: 17.307\n",
      "Running outer fold 2/5\n",
      "scaler fit\n",
      "scaler fit\n",
      "scaler fit\n",
      "scaler fit\n",
      "Best parameter (CV score=-410.916): {'impute__n_neighbors': 3, 'impute__weights': 'distance', 'model__alpha': 1.3888888888888888} RMSE: 22.883\n",
      "Running outer fold 3/5\n",
      "scaler fit\n",
      "scaler fit\n",
      "scaler fit\n",
      "scaler fit\n",
      "Best parameter (CV score=-541.304): {'impute__n_neighbors': 4, 'impute__weights': 'distance', 'model__alpha': 1.0666666666666667} RMSE: 17.711\n",
      "Running outer fold 4/5\n",
      "scaler fit\n",
      "scaler fit\n",
      "scaler fit\n",
      "scaler fit\n",
      "Best parameter (CV score=-527.397): {'impute__n_neighbors': 4, 'impute__weights': 'distance', 'model__alpha': 0.7444444444444444} RMSE: 24.460\n",
      "Running outer fold 5/5\n",
      "scaler fit\n",
      "scaler fit\n",
      "scaler fit\n",
      "scaler fit\n",
      "Best parameter (CV score=-424.396): {'impute__n_neighbors': 4, 'impute__weights': 'distance', 'model__alpha': 1.711111111111111} RMSE: 25.349\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Define the pipeline\n",
    "scaler = CustomScaler(X_new=X_new)\n",
    "imputer = CustomKNNImputer(X_new = X_new)\n",
    "model = Lasso(max_iter=10000)\n",
    "pipe = Pipeline(steps=[('scale', scaler), ('impute', imputer), ('model', model)])\n",
    "\n",
    "param_grid = {'impute__weights': ['uniform', 'distance'], \n",
    "              'impute__n_neighbors': range(3, 10), \n",
    "              'model__alpha': np.linspace(0.1, 3, 10)\n",
    "              }\n",
    "\n",
    "# Define the cross-validation\n",
    "K_outer = 5\n",
    "K_inner = 3\n",
    "outer_cv = KFold(n_splits=K_outer, shuffle=True, random_state=42)\n",
    "inner_cv = KFold(n_splits=K_inner, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform the grid search\n",
    "RMSE = np.zeros(K_outer)\n",
    "for i, (train_idx, test_idx) in enumerate(outer_cv.split(X)):\n",
    "    print(f\"Running outer fold {i+1}/{K_outer}\")\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y_vec[train_idx], y_vec[test_idx]\n",
    "    search = GridSearchCV(pipe, param_grid, cv=inner_cv, scoring='neg_mean_squared_error', n_jobs=-1, refit = True)\n",
    "    search.fit(X_train, y_train)\n",
    "    best_params = search.best_params_\n",
    "\n",
    "    pipe.set_params(**best_params)\n",
    "    pipe.fit(X_train, y_train)\n",
    "    preds = pipe.predict(X_test)\n",
    "\n",
    "    #best_model = result.best_estimator_\n",
    "    #preds = best_model.predict(X_test)\n",
    "\n",
    "    RMSE[i] = np.sqrt(np.mean((preds - y_test)**2))\n",
    "    print(\"Best parameter (CV score=%0.3f):\" % search.best_score_, search.best_params_, 'RMSE:', f\"{RMSE[i]:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without using pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_categorical_bool(inp_array):\n",
    "    N = inp_array.shape[0]\n",
    "    for i in range(N):\n",
    "        for j in range(4):\n",
    "            idx = np.argmax(inp_array[i, 95+(j*5) : 95+(j+1)*5 ])\n",
    "            inp_array[i, 95+(j*5) : 95+(j+1)*5 ] = 0,0,0,0,0\n",
    "            inp_array[i, 95+(j*5) + idx] = 1\n",
    "    return inp_array\n",
    "\n",
    "def custom_scale(scaler, data_X, data_Xnew):\n",
    "    \"\"\" \n",
    "        Scale both X and Xnew based only on their continous values.\n",
    "    \"\"\"\n",
    "    scaler.fit(np.concatenate((data_X[:,:95], data_Xnew[:,:95]), axis = 0))\n",
    "    X_con, Xnew_con = scaler.transform(data_X[:,:95]), scaler.transform(data_Xnew[:,:95])\n",
    "    data_X_norm = np.concatenate((X_con, data_X[:,95:]), axis = 1)\n",
    "    data_Xnew_norm = np.concatenate((Xnew_con, data_Xnew[:,95:]), axis = 1)\n",
    "    all_data = np.concatenate((data_X_norm, data_Xnew_norm), axis = 0)\n",
    "\n",
    "    return scaler, data_X_norm, all_data\n",
    "\n",
    "def custom_transform(scaler, data):\n",
    "    return np.concatenate((scaler.transform(data[:,:95]), data[:,95:]), axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Optimal neighbors:  16 , optimal method: distance , optimal alpha:  1.0666666666666667\n",
      "RMSE: 20.798210960978814\n",
      "1\n",
      "Optimal neighbors:  8 , optimal method: distance , optimal alpha:  0.42222222222222217\n",
      "RMSE: 20.264205977390173\n",
      "2\n",
      "Optimal neighbors:  8 , optimal method: uniform , optimal alpha:  1.3888888888888888\n",
      "RMSE: 16.7453649349476\n",
      "3\n",
      "Optimal neighbors:  8 , optimal method: distance , optimal alpha:  1.3888888888888888\n",
      "RMSE: 22.987312124738324\n",
      "4\n",
      "Optimal neighbors:  8 , optimal method: uniform , optimal alpha:  1.3888888888888888\n",
      "RMSE: 20.49045269384252\n",
      "5\n",
      "Optimal neighbors:  16 , optimal method: distance , optimal alpha:  1.3888888888888888\n",
      "RMSE: 19.483760629671032\n",
      "6\n",
      "Optimal neighbors:  8 , optimal method: uniform , optimal alpha:  1.0666666666666667\n",
      "RMSE: 18.2331960250399\n",
      "7\n",
      "Optimal neighbors:  8 , optimal method: uniform , optimal alpha:  0.7444444444444444\n",
      "RMSE: 18.309026233627\n",
      "8\n",
      "Optimal neighbors:  4 , optimal method: distance , optimal alpha:  1.3888888888888888\n",
      "RMSE: 14.271610024078374\n",
      "9\n",
      "Optimal neighbors:  18 , optimal method: uniform , optimal alpha:  1.0666666666666667\n",
      "RMSE: 23.630563853997966\n",
      "10\n",
      "Optimal neighbors:  8 , optimal method: distance , optimal alpha:  0.42222222222222217\n",
      "RMSE: 29.562419326711762\n",
      "11\n",
      "Optimal neighbors:  18 , optimal method: distance , optimal alpha:  1.0666666666666667\n",
      "RMSE: 21.44643919741229\n",
      "12\n",
      "Optimal neighbors:  18 , optimal method: uniform , optimal alpha:  0.42222222222222217\n",
      "RMSE: 24.00950278930824\n",
      "13\n",
      "Optimal neighbors:  8 , optimal method: distance , optimal alpha:  1.0666666666666667\n",
      "RMSE: 18.637020954466923\n",
      "14\n",
      "Optimal neighbors:  16 , optimal method: uniform , optimal alpha:  1.711111111111111\n",
      "RMSE: 12.195878993417075\n",
      "Mean RMSE: 20.070997647975197\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "K_outer = 15\n",
    "K_inner = 5\n",
    "cv_outer = KFold(n_splits=K_outer, shuffle=True, random_state=42)\n",
    "cv_inner = KFold(n_splits=K_inner, shuffle=True, random_state=42)\n",
    "alphas = np.linspace(0.1, 3, 10)\n",
    "neighbors = range(2, 20, 2)\n",
    "methods = ['uniform', 'distance']\n",
    "RMSE = np.zeros(K_outer)\n",
    "\n",
    "for k1, (train_index, test_index) in enumerate(cv_outer.split(X)):\n",
    "    print(k1)\n",
    "    Xtrain, Xtest = X[train_index], X[test_index]\n",
    "    ytrain, ytest = y_vec[train_index], y_vec[test_index]\n",
    "\n",
    "    errors_inner = np.zeros((K_inner, len(neighbors), len(methods), len(alphas)))\n",
    "    for k2, (train_index_inner, test_index_inner) in enumerate(cv_inner.split(Xtrain)):\n",
    "        Xtrain_inner, Xtest_inner = Xtrain[train_index_inner], Xtrain[test_index_inner]\n",
    "        ytrain_inner, ytest_inner = ytrain[train_index_inner], ytrain[test_index_inner]\n",
    "        scaler, Xtrain_inner_norm, all_inner_data = custom_scale(StandardScaler(), Xtrain_inner, X_new)\n",
    "        Xtest_inner_norm = custom_transform(scaler, Xtest_inner)\n",
    "        \n",
    "        for i, neigh in enumerate(neighbors):\n",
    "            for m, method in enumerate(methods):\n",
    "                imputer = KNNImputer(n_neighbors=neigh, weights=method).fit(all_inner_data)\n",
    "                #Impute data\n",
    "                Xtrain_inner_imputed = transform_to_categorical_bool(imputer.transform(Xtrain_inner_norm))\n",
    "                Xtest_inner_imputed = transform_to_categorical_bool(imputer.transform(Xtest_inner_norm))\n",
    "\n",
    "                for j, alpha in enumerate(alphas):\n",
    "                    model = Lasso(alpha=alpha, max_iter=10000).fit(Xtrain_inner_imputed, ytrain_inner)\n",
    "                    preds_inner = model.predict(Xtest_inner_imputed)\n",
    "                    errors_inner[k2, i, m, j] = np.sum((preds_inner - ytest_inner)**2) #Sum up all squared error\n",
    "\n",
    "    mean_error_inner = errors_inner.mean(axis = 0)\n",
    "    idx = np.unravel_index(np.argmin(mean_error_inner, axis=None), mean_error_inner.shape)\n",
    "    print('Optimal neighbors: ', neighbors[idx[0]], ', optimal method:', methods[idx[1]], ', optimal alpha: ', alphas[idx[2]])\n",
    "\n",
    "    scaler, Xtrain_norm, all_data = custom_scale(StandardScaler(), Xtrain, X_new)\n",
    "    Xtest_norm = custom_transform(scaler, Xtest)\n",
    "    imputer = KNNImputer(n_neighbors=neighbors[idx[0]], weights=methods[idx[1]]).fit(all_data)\n",
    "    Xtrain_imputed = transform_to_categorical_bool(imputer.transform(Xtrain_norm))\n",
    "    Xtest_imputed = transform_to_categorical_bool(imputer.transform(Xtest_norm))\n",
    "    best_inner_model = Lasso(alpha=alphas[idx[2]], max_iter=10000).fit(Xtrain_imputed, ytrain)\n",
    "    preds_outer = best_inner_model.predict(Xtest_imputed)\n",
    "\n",
    "    RMSE[k1] = np.sqrt(np.mean((preds_outer - ytest)**2))\n",
    "    print('RMSE:', RMSE[k1])\n",
    "\n",
    "print('Mean RMSE:', RMSE.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
